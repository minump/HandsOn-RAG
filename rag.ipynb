{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG - Retrieval-Augmented Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap\n",
    "\n",
    "![With and Without RAG](notebook_images/rag-with-without.png \"With and Without RAG\") \n",
    "\n",
    "![RAG](notebook_images/rag-before-after.png \"RAG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG\n",
    "\n",
    "#### Retrieval\n",
    "- Setup a knowledge base \n",
    "- Retrieve documents relevant to the user query\n",
    "\n",
    "#### Generation\n",
    "- Using LLMs\n",
    "- Use the retrieved documents as context\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG - Retrieval Steps\n",
    "\n",
    "1. Prepare data \n",
    "2. Create a vector store and insert data\n",
    "3. Search the vector store and retrieve relevant documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG - *Retrieval*-Augmented Generation\n",
    "\n",
    "### Knowledge DB\n",
    "\n",
    "* Vector database (Beginners [blog 1](https://medium.com/data-and-beyond/vector-databases-a-beginners-guide-b050cbbe9ca0), Pinecone [blog 2](https://www.pinecone.io/learn/vector-database/))\n",
    "\n",
    "\n",
    "![knowledge DB](notebook_images/knowledge-db.png \"Knowledge DB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG - *Retrieval*-Augmented Generation\n",
    "\n",
    "### Vector DB Retrieval\n",
    "\n",
    "![Vector DB Retrieval](notebook_images/vectordb-retrieval.png \"Vector DB Retrieval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG - Retrieval Steps\n",
    "\n",
    "1. Prepare data \n",
    "2. Create a vector store and insert data\n",
    "3. Search the vector store and retrieve relevant documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# create and configure logger\n",
    "logging.basicConfig(level=logging.INFO, datefmt='%Y-%m-%dT%H:%M:%S',\n",
    "                    format='%(asctime)-15s.%(msecs)03dZ %(levelname)-7s : %(name)s - %(message)s',\n",
    "                    handlers=[logging.StreamHandler(sys.stdout)]\n",
    "                    )\n",
    "# create log object with current module name\n",
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prepare data\n",
    "- Load data from different sources\n",
    "- Will be using proceedings from [Arctic data symposium 2023](https://arcticdata.io/catalog/portals/pisymposium2023).\n",
    "- Eg: [Proceedings final report](https://permafrostcoasts.org/wp-content/uploads/2024/08/2023-PI-Symposium-final-report-web.pdf), [participant bios](https://arcticdata.io/metacat/d1/mn/v2/object/urn:uuid:6e613b84-842c-4ac9-993d-a863d7040aa5) \n",
    "- Data in data/docs directory. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data Loaders\n",
    "- Langchain provides different data loaders for different file types\n",
    "- Data loaded in Langchain Document class format [document class](https://api.python.langchain.com/en/latest/documents/langchain_core.documents.base.Document.html)\n",
    "\n",
    "![Langchain document class](notebook_images/langchain-document-class.png \"Langchain document class\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loaders\n",
    "from langchain_community.document_loaders import CSVLoader, DataFrameLoader, PyPDFLoader, Docx2txtLoader, UnstructuredRSTLoader, DirectoryLoader\n",
    "\n",
    "\n",
    "class DataLoaders:\n",
    "    \"\"\"\n",
    "    various data loaders\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dir_path):\n",
    "        self.data_dir_path = data_dir_path\n",
    "    \n",
    "    def csv_loader(self):\n",
    "        csv_loader_kwargs = {\n",
    "                            \"csv_args\":{\n",
    "                                \"delimiter\": \",\",\n",
    "                                \"quotechar\": '\"',\n",
    "                                },\n",
    "                            }\n",
    "        dir_csv_loader = DirectoryLoader(self.data_dir_path, glob=\"**/*.csv\", use_multithreading=True,\n",
    "                                    loader_cls=CSVLoader, \n",
    "                                    loader_kwargs=csv_loader_kwargs,\n",
    "                                    )\n",
    "        return dir_csv_loader\n",
    "    \n",
    "    def pdf_loader(self):\n",
    "        dir_pdf_loader = DirectoryLoader(self.data_dir_path, glob=\"**/*.pdf\",\n",
    "                                    loader_cls=PyPDFLoader,\n",
    "                                    )\n",
    "        return dir_pdf_loader\n",
    "    \n",
    "    def word_loader(self):\n",
    "        dir_word_loader = DirectoryLoader(self.data_dir_path, glob=\"**/*.docx\",\n",
    "                                    loader_cls=Docx2txtLoader,\n",
    "                                    )\n",
    "        return dir_word_loader\n",
    "    \n",
    "    def rst_loader(self):\n",
    "        rst_loader_kwargs = {\n",
    "                        \"mode\":\"single\"\n",
    "                        }\n",
    "        dir_rst_loader = DirectoryLoader(self.data_dir_path, glob=\"**/*.rst\",\n",
    "                                    loader_cls=UnstructuredRSTLoader, \n",
    "                                    loader_kwargs=rst_loader_kwargs\n",
    "                                    )\n",
    "        return dir_rst_loader\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-06T12:11:10.033Z INFO    : __main__ - Loading files from directory data\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "data_dir_path =  \"data\"\n",
    "data_loader = DataLoaders(data_dir_path=data_dir_path)\n",
    "log.info(\"Loading files from directory %s\", data_dir_path)\n",
    "dir_csv_loader = data_loader.csv_loader()\n",
    "dir_word_loader = data_loader.word_loader()\n",
    "dir_pdf_loader = data_loader.pdf_loader()\n",
    "dir_rst_loader = data_loader.rst_loader()\n",
    "csv_data = dir_csv_loader.load()\n",
    "word_data = dir_word_loader.load()\n",
    "pdf_data = dir_pdf_loader.load()\n",
    "rst_data = dir_rst_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='www.afm-journal.de© 2020 Wiley-VCH GmbH 2006683 (1 of 9)Full PaPer\n",
      "Direct Ink Writing of Polymer Composite Electrolytes \n",
      "with Enhanced Thermal Conductivities\n",
      "Meng Cheng, Ajaykrishna Ramasubramanian, Md Golam Rasul, Yizhou Jiang, Yifei Yuan, \n",
      "Tara Foroozan, Ramasubramonian Deivanayagam, Mahmoud Tamadoni Saray, \n",
      "Ramin Rojaee, Boao Song, Vitaliy Robert Yurkiv, Yayue Pan, Farzad Mashayek, \n",
      "and Reza Shahbazian-Yassar*\n",
      "Proper distribution of thermally conductive nanomaterials in polymer \n",
      "batteries offers new opportunities to mitigate performance degradations \n",
      "associated with local hot spots and safety concerns in batteries. Herein, a \n",
      "direct ink writing (DIW) method is utilized to fabricate polyethylene oxide (PEO) composite polymers electrolytes (CPE) embedded with silane-treated \n",
      "hexagonal boron nitride (S-hBN) platelets and free of any volatile organic \n",
      "solvents. It is observed that the S-hBN platelets are well aligned in the printed CPE during the DIW process. The in-plane thermal conductivity  \n",
      "of the printed CPE with the aligned S-hBN platelets is 1.031 W \n",
      "−1 K−1, which \n",
      "is about 1.7 times that of the pristine CPE with the randomly dispersed \n",
      "S-hBN platelets (0.612 W −1 K−1). Thermal imaging shows that the peak tem-\n",
      "perature (° C) of the printed electrolytes is 24.2% lower than that of the CPE \n",
      "without S-hBN, and 10.6% lower than that of the CPE with the randomly \n",
      "dispersed S-hBN, indicating a superior thermal transport property. Lithium-ion half-cells made with the printed CPE and LiFePO\n",
      "4 cathode displayed \n",
      "high specific discharge capacity of 146.0 mAh g−1 and stable Coulombic \n",
      "efficiency of 91% for 100 cycles at room temperature. This work facilitates \n",
      "the development of printable thermally-conductive polymers for safer bat-\n",
      "tery operations.\n",
      "DOI: 10.1002/adfm.202006683M. Cheng, Dr. A. Ramasubramanian, M. G. Rasul, Y . Jiang, Dr. Y . Yuan,  \n",
      "Dr. T. Foroozan, Dr. R. Deivanayagam, M. Tamadoni Saray, Dr. R. Rojaee,  \n",
      "Dr. B. Song, Dr. V. R. Yurkiv, Prof. Y . Pan, Prof. F. Mashayek,  Prof. R. Shahbazian-YassarDepartment of Mechanical and Industrial EngineeringUniversity of Illinois at ChicagoChicago, IL 60607, USAE-mail: rsyassar@uic.edu\n",
      "The ORCID identification number(s) for the author(s) of this article can be found under https://doi.org/10.1002/adfm.202006683.have posed significant challenges.[4,5] The \n",
      "formation of localized heat spots can lead \n",
      "to thermal runaway in batteries and safety \n",
      "concerns.[6–8]\n",
      "Compared with carbonate-based liquid \n",
      "electrolytes, polymer electrolytes gener -\n",
      "ally present higher electrochemical sta-bility, better mechanical properties, and \n",
      "increased flexibility.\n",
      "[9] While polymer elec-\n",
      "trolytes are considered to be a safer option to replace the organic liquid electrolytes in \n",
      "Li-ion batteries, the low thermal conduc-\n",
      "tivity of polymers poses challenges to the heat dissipation.\n",
      "[9–11] Chen et  al. reported \n",
      "that due to the low thermal conductivity of polymer electrolytes, the thermal gradient \n",
      "increased in the cell stack.\n",
      "[12,13] As a result, \n",
      "the polymer electrolytes can be melted \n",
      "down when the battery temperature rises \n",
      "to the polymer melting point and causes a \n",
      "potential internal short circuit.[14]\n",
      "Hexagonal boron nitride (hBN) mate-\n",
      "rials with outstanding thermal conductivity (up to 2000 W m\n",
      "−1 K−1) are considered \n",
      "to be promising fillers to improve the \n",
      "thermal conductivity of polymer separators and electrolytes.[15,16]  \n",
      "Vishwakarma et  al. presented a polyvinylidene fluoride (PVdF) gel polymer electrolytes with BN/Al\n",
      "2O3 ceramic nano/micropar -\n",
      "ticles.[16] The thermal conductivity of the electrolytes could be \n",
      "up to 1.2 W m−1 K−1, which was 13 times higher than the inac-\n",
      "tivated PVdF membrane. However, the internal resistance of the electrolytes also increased since the volume fraction of the elec-\n",
      "trolyte mixture was reduced by the high loading of additions. \n",
      "The polymer separator and electrolytes with improved thermal conductivity have been employed in Li-ion batteries to promote heat dissipation and reduce thermal stress in batteries.\n",
      "[17,18] Hu’s \n",
      "group reported a thermally conductive separator coated with boron-nitride nanosheets.\n",
      "[17] The temperature spike of BN-coated \n",
      "separator was ≈ 32% lower than that of the pristine separator at \n",
      "the hotspot. The same group further fabricated PVdF-hexafluor -\n",
      "opropylene separator with BN nanosheets via an extrusion-based printing technique.\n",
      "[18] Compared with the commercial separator, \n",
      "the maximum temperature of the printed BN-separator was lower, suggesting that the BN-separator provided a more homo-\n",
      "genous temperature distribution.1. Introduction\n",
      "In the past two decades, lithium-ion batteries have successfully \n",
      "penetrated the market of electric vehicles and portable electronics, mainly owing to their high-power density, long cycle life, and low \n",
      "self-discharge properties.\n",
      "[1–3] However, the safety concerns of \n",
      "the conventional Li-ion batteries with organic liquid electrolytes \n",
      "Adv. Funct. Mater. 2021, 31, 2006683\n",
      "' metadata={'source': 'data/Adv Funct Materials - 2020 - Cheng - Direct Ink Writing of Polymer Composite Electrolytes with Enhanced Thermal.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "for doc in pdf_data:\n",
    "    print(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of PDF documents:  125\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of PDF documents: \", len(pdf_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Format into text and metadata\n",
    "- Convert data to a list of texts and metadata \n",
    "- Metadata can be used for filtering the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get text and metadata from the data\n",
    "def get_text_metadatas(csv_data=None, pdf_data=None, word_data=None, rst_data=None):\n",
    "    \"\"\"\n",
    "    Each document class has page_content and metadata properties\n",
    "    Separate text and metadata content from Document class\n",
    "    Have custom metadata if needed\n",
    "    \"\"\"\n",
    "    csv_texts = [doc.page_content for doc in csv_data]\n",
    "    # custom metadata\n",
    "    csv_metadatas = [{'source': doc.metadata['source'], 'row_page': doc.metadata['row']} for doc in csv_data]   # metadata={'source': 'filename.csv', 'row': 0}\n",
    "    pdf_texts = [doc.page_content for doc in pdf_data]\n",
    "    pdf_metadatas = [{'source': doc.metadata['source'], 'row_page': doc.metadata['page']} for doc in pdf_data]  # metadata={'source': 'data/filename.pdf', 'page': 8}\n",
    "    word_texts = [doc.page_content for doc in word_data]\n",
    "    word_metadatas = [{'source': doc.metadata['source'], 'row_page': ''} for doc in word_data] \n",
    "    rst_texts = [doc.page_content for doc in rst_data]\n",
    "    rst_metadatas = [{'source': doc.metadata['source'], 'row_page': ''} for doc in rst_data]         # metadata={'source': 'docs/images/architecture/index.rst'}\n",
    "\n",
    "    texts = csv_texts + pdf_texts + word_texts + rst_texts\n",
    "    metadatas = csv_metadatas + pdf_metadatas + word_metadatas + rst_metadatas\n",
    "    return texts, metadatas\n",
    "\n",
    "\n",
    "texts , metadatas = get_text_metadatas(csv_data, pdf_data, word_data, rst_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Chunking\n",
    "\n",
    "![Chunk Optimization](notebook_images/rag-chunking.png \"Chunk Optimization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Chunking\n",
    "- Split texts into chunks for embedding\n",
    "- Return a list of document chunks (list of langchain [document class](https://api.python.langchain.com/en/latest/documents/langchain_core.documents.base.Document.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from typing import List\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        separators=[\n",
    "            \"\\n\\n\", \"\\n\", \". \", \" \", \"\"\n",
    "        ]  # try to split on paragraphs... fallback to sentences, then chars, ensure we always fit in context window\n",
    "    )\n",
    "\n",
    "docs: List[Document] = text_splitter.create_documents(texts=texts, metadatas=metadatas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='www.afm-journal.de© 2020 Wiley-VCH GmbH 2006683 (1 of 9)Full PaPer\n",
      "Direct Ink Writing of Polymer Composite Electrolytes \n",
      "with Enhanced Thermal Conductivities\n",
      "Meng Cheng, Ajaykrishna Ramasubramanian, Md Golam Rasul, Yizhou Jiang, Yifei Yuan, \n",
      "Tara Foroozan, Ramasubramonian Deivanayagam, Mahmoud Tamadoni Saray, \n",
      "Ramin Rojaee, Boao Song, Vitaliy Robert Yurkiv, Yayue Pan, Farzad Mashayek, \n",
      "and Reza Shahbazian-Yassar*\n",
      "Proper distribution of thermally conductive nanomaterials in polymer \n",
      "batteries offers new opportunities to mitigate performance degradations \n",
      "associated with local hot spots and safety concerns in batteries. Herein, a \n",
      "direct ink writing (DIW) method is utilized to fabricate polyethylene oxide (PEO) composite polymers electrolytes (CPE) embedded with silane-treated \n",
      "hexagonal boron nitride (S-hBN) platelets and free of any volatile organic \n",
      "solvents. It is observed that the S-hBN platelets are well aligned in the printed CPE during the DIW process. The in-plane thermal conductivity  \n",
      "of the printed CPE with the aligned S-hBN platelets is 1.031 W \n",
      "−1 K−1, which \n",
      "is about 1.7 times that of the pristine CPE with the randomly dispersed \n",
      "S-hBN platelets (0.612 W −1 K−1). Thermal imaging shows that the peak tem-\n",
      "perature (° C) of the printed electrolytes is 24.2% lower than that of the CPE \n",
      "without S-hBN, and 10.6% lower than that of the CPE with the randomly \n",
      "dispersed S-hBN, indicating a superior thermal transport property. Lithium-ion half-cells made with the printed CPE and LiFePO\n",
      "4 cathode displayed \n",
      "high specific discharge capacity of 146.0 mAh g−1 and stable Coulombic \n",
      "efficiency of 91% for 100 cycles at room temperature. This work facilitates \n",
      "the development of printable thermally-conductive polymers for safer bat-\n",
      "tery operations.\n",
      "DOI: 10.1002/adfm.202006683M. Cheng, Dr. A. Ramasubramanian, M. G. Rasul, Y . Jiang, Dr. Y . Yuan,  \n",
      "Dr. T. Foroozan, Dr. R. Deivanayagam, M. Tamadoni Saray, Dr. R. Rojaee,  \n",
      "Dr. B. Song, Dr. V. R. Yurkiv, Prof. Y . Pan, Prof. F. Mashayek,  Prof. R. Shahbazian-YassarDepartment of Mechanical and Industrial EngineeringUniversity of Illinois at ChicagoChicago, IL 60607, USAE-mail: rsyassar@uic.edu\n",
      "The ORCID identification number(s) for the author(s) of this article can be found under https://doi.org/10.1002/adfm.202006683.have posed significant challenges.[4,5] The \n",
      "formation of localized heat spots can lead \n",
      "to thermal runaway in batteries and safety \n",
      "concerns.[6–8]\n",
      "Compared with carbonate-based liquid \n",
      "electrolytes, polymer electrolytes gener -\n",
      "ally present higher electrochemical sta-bility, better mechanical properties, and \n",
      "increased flexibility.\n",
      "[9] While polymer elec-\n",
      "trolytes are considered to be a safer option to replace the organic liquid electrolytes in \n",
      "Li-ion batteries, the low thermal conduc-\n",
      "tivity of polymers poses challenges to the heat dissipation.\n",
      "[9–11] Chen et  al. reported \n",
      "that due to the low thermal conductivity of polymer electrolytes, the thermal gradient \n",
      "increased in the cell stack.\n",
      "[12,13] As a result, \n",
      "the polymer electrolytes can be melted \n",
      "down when the battery temperature rises \n",
      "to the polymer melting point and causes a \n",
      "potential internal short circuit.[14]\n",
      "Hexagonal boron nitride (hBN) mate-\n",
      "rials with outstanding thermal conductivity (up to 2000 W m\n",
      "−1 K−1) are considered \n",
      "to be promising fillers to improve the' metadata={'source': 'data/Adv Funct Materials - 2020 - Cheng - Direct Ink Writing of Polymer Composite Electrolytes with Enhanced Thermal.pdf', 'row_page': 0}\n",
      "Number of documents:  265\n"
     ]
    }
   ],
   "source": [
    "print(docs[0])\n",
    "print(\"Number of documents: \", len(docs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Embeddings\n",
    "\n",
    "- Mathematical representations of data points in a high-dimensional space. \n",
    "- In the context of natural language processing:\n",
    "    1. Word Embeddings: Individual words are represented as real-valued vectors in a multi-dimensional space.\n",
    "    2. Semantic Capture: These embeddings capture the semantic meaning and relationships of the text.\n",
    "    3. Similarity Principle: Words with similar meanings tend to have similar vector representations.\n",
    "\n",
    "- We will be using OpenAI embeddings\n",
    "- text-embedding-ada-002 model for embeddings, which has a maximum token limit of 8191 according to OpenAI documentation.\n",
    "- HF Embedding models leaderboard [link](https://huggingface.co/spaces/mteb/leaderboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings \n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG - Retrieval Steps\n",
    "\n",
    "~~1. Prepare data~~\n",
    "\n",
    "2. Create a vector store and insert data\n",
    "\n",
    "3. Search the vector store and retrieve relevant documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Vector Store\n",
    "\n",
    "![Inserting into DB](notebook_images/inserting-db.png \"Inserting into DB\")\n",
    "\n",
    "Source Credits : [Blog.demir](https://blog.demir.io/hands-on-with-rag-step-by-step-guide-to-integrating-retrieval-augmented-generation-in-llms-ac3cb075ab6f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Vector Store\n",
    "\n",
    "- We will use [Qdrant](https://qdrant.tech/) vector store for this example\n",
    "- For today we will use local memory as the vector store\n",
    "- Qdrant has a docker image that can be used to create a vector store and hosted remotely\n",
    "Eg: [Qdrant docker container running locally](http://localhost:6333/dashboard)\n",
    "\n",
    "- Blog post on vector stores [link](https://medium.com/google-cloud/vector-databases-are-all-the-rage-872c888fa348)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-06T12:12:37.962Z INFO    : httpx - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-06T12:12:39.865Z INFO    : httpx - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-06T12:12:41.871Z INFO    : httpx - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-06T12:12:43.316Z INFO    : httpx - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-06T12:12:44.658Z INFO    : httpx - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-06T12:12:45.392Z INFO    : httpx - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "# creating a qdrant vector store in local memory\n",
    "\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "\n",
    "# qdrant collection name\n",
    "collection_name = os.getenv('QDRANT_COLLECTION_NAME', \"data-collection\")\n",
    "\n",
    "# create vector store in local memory\n",
    "vectorstore = Qdrant.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embeddings,\n",
    "    location=\":memory:\",  # Local mode with in-memory storage only\n",
    "    collection_name=collection_name,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG - Retrieval Steps\n",
    "\n",
    "~~1. Prepare data~~\n",
    "\n",
    "~~2. Create a vector store and insert data~~\n",
    "\n",
    "3. Search the vector store and retrieve relevant documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Retrieve relevant documents\n",
    "Create a retriever from the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retriever to retrieve relevant snippets\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG - Retrieval Steps\n",
    "\n",
    "~~1. Prepare data~~\n",
    "\n",
    "~~2. Create a vector store and insert data~~\n",
    "\n",
    "~~3. Search the vector store and retrieve relevant documents~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG - Retrieval-Augmented *Generation*\n",
    "\n",
    "\n",
    "![RAG LLM](notebook_images/rag-llm.png \"RAG LLM\")\n",
    "\n",
    "![LLM prompting](notebook_images/rag-prompting.png \"LLM Prompting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Call LLM\n",
    "\n",
    "### 4.1 Prompting\n",
    "- Use a prompt template [link](https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.prompt.PromptTemplate.html)\n",
    "    - includes input parameters that can be dynamically changed\n",
    "- Use Langchain hub to pull prompts [link](https://smith.langchain.com/hub)\n",
    "    - easy to share and reuse prompts\n",
    "    - can see what are the popular prompts for specific use cases\n",
    "    - Eg: [rag-prompt](https://smith.langchain.com/hub/rlm/rag-prompt)\n",
    "- Use a custom prompt\n",
    "```\n",
    "qa_prompt_template = \"\"\"Use the following pieces of context to answer the question at the end. Please follow the following rules:\n",
    "    1. If the question has some initial findings, use that as context.\n",
    "    2. If you don't know the answer, don't try to make up an answer. Just say **I can't find the final answer but you may want to check the following sourcess** and add the source documents as a list.\n",
    "    3. If you find the answer, write the answer in a concise way and add the list of sources that are **directly** used to derive the answer. Exclude the sources that are irrelevant to the final answer.\n",
    "\n",
    "    {context}\n",
    "\n",
    "    Question: {question}\n",
    "    Helpful Answer:\"\"\"\n",
    "\n",
    "rag_chain_prompt = PromptTemplate.from_template(qa_prompt_template) \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Prompting\n",
    "\n",
    "rlm/rag-prompt from Langchain\n",
    "\n",
    "![RLM RAG prompt](notebook_images/rlm-rag-prompt.png \"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompting\n",
    "\n",
    "from langchain import hub\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Call LLM\n",
    "- We will use \n",
    "    - OpenAI GPT-4o-mini and \n",
    "    - Ollama llama3.2 model (hosted by NCSA)\n",
    "- Each model has its own formats and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formatting the documents as a string before calling the LLM\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call open ai GPT-4o-mini\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# create a chat openai model\n",
    "llm: ChatOpenAI = ChatOpenAI(\n",
    "            temperature=0,\n",
    "            model=\"gpt-4o-mini\",\n",
    "            max_retries=500,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-06T10:06:53.653Z INFO    : httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='There is no official \"capital of the world,\" as each country has its own capital city. However, some cities are often referred to as global capitals due to their significant influence in international politics, finance, culture, and diplomacy. Examples include New York City (home to the United Nations), London, and Washington, D.C. Each of these cities plays a crucial role on the world stage, but there is no single city that serves as the capital of the entire world.', response_metadata={'token_usage': {'completion_tokens': 95, 'prompt_tokens': 15, 'total_tokens': 110, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0ba0d124f1', 'finish_reason': 'stop', 'logprobs': None}, id='run-78e59ba3-36f9-4689-a8b7-791266b4d593-0', usage_metadata={'input_tokens': 15, 'output_tokens': 95, 'total_tokens': 110})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call GPT4o-mini\n",
    "llm.invoke(\"What is the capital of the world?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 RAG \n",
    "\n",
    "![RAG system](notebook_images/rag-system.png \"RAG system\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 RAG Chain\n",
    "Combining it all together\n",
    "\n",
    "- Context is the retrieved docs from the retriever/vector db\n",
    "- RunnablePassthrough() is used to pass the user query as is to the chain\n",
    "- format_docs is used to format the documents as a string\n",
    "- prompt is used to call the prompt template\n",
    "- llm is used to call the LLM\n",
    "- StrOutputParser() is used to parse the output from the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rag chain\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "openai_rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-06T12:13:52.648Z INFO    : httpx - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-06T12:13:54.651Z INFO    : httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The materials used are poly(vinylidene fluoride) (PVDF) and poly(vinylidene fluoride-co-hexaﬂuoropropylene) (PVDF-HFP). These polymers are prepared through direct-ink-writing techniques for applications in sensing and energy storage. They exhibit various morphologies and properties suitable for advanced electronic devices.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call openai rag chain\n",
    "openai_rag_chain.invoke(\"What material is used?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-06T12:14:27.490Z INFO    : httpx - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-06T12:14:28.708Z INFO    : httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The yield stress values for the materials mentioned are 1000 Pa for NIPAM/Lap and 300 Pa for NIPAM/Lap/NaPyrPh. Yield stress is typically measured in pascals (Pa). It represents the minimum stress required to induce flow in a material.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_rag_chain.invoke(\"What is the yield stress value or unit?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-06T12:15:04.344Z INFO    : httpx - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-06T12:15:05.890Z INFO    : httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Yes, there are epoxy-based resins, including those used in 3D printing technologies. These resins can be formulated with various additives, such as acrylates and nanoparticles, to enhance their properties for specific applications. The context mentions the use of epoxy oligomers and the development of inks for direct-ink write (DIW) printing methods.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_rag_chain.invoke(\"Is there any epoxy, epoxy-based resin?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-06T12:15:08.719Z INFO    : httpx - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-06T12:15:11.185Z INFO    : httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The print temperature was initially set to 45°C and later increased to 80°C for post-curing. The printing speed was a maximum of 180 mm/s, and the nozzle diameter used was 1.63 mm. Additionally, a 22 GA nozzle with an inner diameter of 0.41 mm was also mentioned for different printed architectures.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_rag_chain.invoke(\"What was the print temperature, speed, nozzle diameter?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call openai rag chain\n",
    "# This should ideally give \"I dont know\" - different from the llm.invoke() method where we do not give a custom prompt\n",
    "openai_rag_chain.invoke(\"What is the capital of the world?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call ollama llama3:latest\n",
    "\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "ollama_api_key = os.getenv('OLLAMA_API_KEY')\n",
    "ollama_jwt_token = os.getenv('OLLAMA_JWT_TOKEN')\n",
    "ollama_headers = {\"Authorization\": f\"Bearer {ollama_api_key}\"}\n",
    "\n",
    "# create a ollama model\n",
    "ollamallm: Ollama = Ollama(\n",
    "    base_url=\"https://ollama.software.ncsa.illinois.edu/ollama\",\n",
    "    model=\"llama3.2:latest\",\n",
    "    headers=ollama_headers\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call llama3 model\n",
    "ollamallm.invoke(\"What is the capital of the world?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ollama rag chain\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "ollama_rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | ollamallm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call ollama rag chain\n",
    "ollama_rag_chain.invoke(\"Who is the president of USA?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## adding sources to openai rag chain\n",
    "\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "openai_rag_chain_from_docs = (\n",
    "    RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "openai_rag_chain_with_source = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ").assign(answer=openai_rag_chain_from_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call openai rag chain with source\n",
    "# this will return the answer and the sources (context)\n",
    "openai_rag_chain_with_source.invoke(\"What were the goals of the symposium?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_rag_chain_with_source.invoke(\"Why is tundra restoration and rehabilitation important\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_rag_chain_with_source.invoke(\"Who is Brenadette Adams?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Steps\n",
    "\n",
    "1. Prepare data \n",
    "2. Create a vector store and insert into db\n",
    "3. Search the vector store and retrieve relevant documents\n",
    "4. Call LLM with the user query and the retrieved documents\n",
    "4. Return the LLM response to the user"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
